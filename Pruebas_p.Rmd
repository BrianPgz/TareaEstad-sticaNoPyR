---
title: "Tarea_Est_1"
output:
  html_document:
    keep_md: yes
  pdf_document: default
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
 
```


## Pruebas de bondad de ajuste
## Problema 3
La siguiente muestra aleatoria hace referencia a los rendimientos positivos de
cierta acción a lo largo del tiempo.

0.2513, 0.2566, 0.3459, 0.6379, 2.0505, 1.803, 2.1906,
1.5299, 0.35005, 0.3128, 1.2726, 2.3674, 2.3214, 2.4373, 0.6548

Llamamos a la libreria nortest para hacer la prueba lilliforce hasta el final.
```{r echo=TRUE}
library(nortest)
```
Ho: La muestra sigue una distribución normal VS Ha: La muestra no sigue una distribución normal

Metemos los datos en un vector y ordenamos los datos.

```{r echo=TRUE}
Dirty_data=c(0.2513, 0.2566, 0.3459, 0.6379, 2.0505, 1.803, 2.1906,
             1.5299, 0.35005, 0.3128, 1.2726, 2.3674, 2.3214, 2.4373, 0.6548)
Data=sort(Dirty_data)
```

```{r echo=FALSE}
Data
```


Como queremos probar normalidad pero no sabemos los parámetros tenemos que estimarlos, primero queremos hacer una función para calcular la varianza muestral.


```{r echo=TRUE}
S2<-function(x){
  mean_aux=mean(x)
  n_aux=length(x)
  s2=0
  for (i in x){
    s2=s2+(i-mean_aux)^2
  }
  s2=s2/(n_aux-1)
  return(s2)
}

```

Calculamos los estimadores máximos verosímiles. 

```{r echo=TRUE}
mean_est=mean(Data)
S2_est=S2(Data)
n=length(Data)

```

```{r echo=FALSE}
mean_est
S2_est
n
```

Calculamos la función de distribución empírica necesaria para la prueba de lillieforce, donde "ecdf" es la función para crear la distribución empírica, "f_n" son los percentiles de la distribución empírica y "f_r" son los percentiles de la distribución pero desplazados una unidad. 


```{r echo=TRUE}
f_emp=ecdf(Data)
f_n=f_emp(Data)
f_r=f_n-(1/n) 
```

Para para prueba de lillieforce necesitamos estandarizar los datos. 

```{r echo=TRUE}
Z=(Data-mean_est)/sqrt(S2_est)
```

```{r echo=FALSE}
Z
```

Ahora usaremos la función de distribución de una normal estandar para los valores antes calculados. 

```{r echo=TRUE}
Probas=pnorm(Z)
```

```{r echo=FALSE}
Probas
```


Tenemos que calcular: $$D_{i}^{+}= | \phi(Z_{i}) - \frac{i}{n}|$$  
$$D_{i}^{-}= | \phi(Z_{i}) - \frac{i-1}{n}|$$
```{r echo=TRUE}
Di_p=abs(Probas-f_n)
Di_n=abs(Probas-f_r)
```

Visualizamos todos los cálculos. 

```{r echo=TRUE}
Visual=data.frame(Dirty_data,Data,Z,Probas,Di_p,Di_n)
```

```{r echo=FALSE}
Visual
```

Definimos $$D^{+}= max\{D_{i}^{+}\}$$ $$D^{-}= max\{D_{i}^{-}\}$$ 
 
```{r echo=TRUE}
D_p=max(Di_p)
D_n=max(Di_n)
```

```{r echo=FALSE}
D_p
D_n
```

Definimos $$D= max\{ D^{+}, D^{-} \}$$

```{r echo=TRUE}
Dn=max(D_p,D_n)
```


```{r echo=FALSE}
Dn
```


Declaramos nuestro nivel de significancia $$\alpha = 0.10$$ entonces $$1-\alpha = 0.90$$.

```{r echo=F}
conf=0.90
alpha=1-conf
```

Comparamos con el nivel crítico $$ W_{0.10}^{15}= 0.2016 $$, para el tamaño de muestra 15 en tablas.

```{r echo=TRUE}
Est=0.2016
Rechazamos_H0=Dn>Est

```

```{r echo=FALSE}
Rechazamos_H0
```

Como $$D > W_{0.10}^{15}$$, rechazamos Ho y por lo tanto no hay evidencia para que los datos sigan una distribución $$ N(\mu,\sigma^2) $$

Hacemos la prueba en unas líneas. 

```{r echo=TRUE}
p_value=lillie.test(Data)[[2]]

Rechazamos_p_value=p_value<alpha
```

```{r echo=FALSE}
p_value
Rechazamos_p_value
```

Confirmando la prueba anterior. 


El gerente del banco asume que la muestra se distribuye sigue una distribución lognormal con media 0 y varianza 1. Realice la prueba correspondiente para verificar la suposición del gerente con un nivel de significancia alpha = 0.01. 

Llamamos a la función de distribución de una lognormal.

```{r echo=TRUE}
ProbasB=plnorm(Data) 
```


```{r echo=FALSE}
ProbasB
```

Calculamos $ D_{i}^{+}$ y $D_{i}^{-} $

```{r echo=TRUE}
Di_pB=abs(ProbasB-f_n)
Di_nB=abs(ProbasB-f_r)

```

Ahora para $D^{+} \quad D^{-}$

```{r echo=TRUE}
D_pB=max(Di_pB)
#Calculamos D-
D_nB=max(Di_nB)
```

Entonces obtenemos $D$
```{r echo=TRUE}
DnB=max(D_pB,D_nB)
```

```{r echo=FALSE}
DnB
```

Declaramos nuestro nivel de significancia $$\alpha = 0.01$$ entonces $$1-\alpha = 0.99$$. 

```{r echo=FALSE}
alphaB=0.01
confB=1-alpha
```

Tenemos que en tablas $$W_{0.01}^{15}=0.40420$$


```{r echo=TRUE}
EstB=0.40420

Rechazamos_H0B=DnB>EstB

```

```{r echo=FALSE}
Rechazamos_H0B
```

Se cumple que $$W_{0.01}^{15} > D$$ entonces no hay evidencia para rechazar Ho, entonces 
los datos siguen una distribución lognormal con media de 1 y varianza 0.

Usamos la prueba específicando la distribución lognormal con sus parámetros.

```{r echo=TRUE}
p_valueB=ks.test(Data,plnorm,0,1)[[2]]

Rechazamos_p_valueB=p_valueB<alphaB
```

```{r echo=FALSE}
p_valueB
Rechazamos_p_valueB
```

Confirmamos la prueba anterior. 


## Pruebas de bondad de ajuste
## Problema 4


Un cierto banco otorga crédito a las personas con una tasa preferencial, de tal
manera que los acreditados pueden pagar en cualquier momento desde que piden
el prestamo hasta 8 semanas posteriores para que les sea respetada la tasa
preferencial . Se seleccionaron aleatoriamente a 1,000 personas y observaron su
comportamiento, generando de esta manera la siguiente tabla de frecuencia:

```{r echo=TRUE}
intervalos <- c( "Menos de 1 semana","1<= x <2" , "2<= x <3","3<= x <4","4<= x <5","5<= x <6","6<= x <7","7<= x <8","Más de 8 semanas")
oi <- c(64,195,287,241,140,51,25,4,1)

tabla <- data.frame(oi,row.names = intervalos )
tabla

```

Observamos la cantidad real de personas. 
```{r echo=TRUE}
k=sum(oi)
print(k)
```

Sea X v.a. que modela semanas completas que se tarda el cliente en hacer el pago. 

Enunciamos la prueba de hipótesis: 

Ho: Se sigue una distribución Bin(n=10,p=0.25)  VS   Ha: No se sigue una distribución Bin(n=10,p=0.25)

Nuestros parámetros son: 

```{r echo=TRUE}
p=0.25
n=10
```
Los datos se agruparon en nueve diferentes clasificaciones $c_{i} \quad i\in \{0,1,...,8 \}$.

```{r echo=TRUE}
length(oi)

```



Nuestras observaciones fueron: 

```{r echo=TRUE}
oi=c(64,195,287,241,140,51,25,4,1)
```

Calculamos las probabilidades $p_{i}$ con la distribución que propusimos, se itera desde cero ya que tenemos la clasificación 0. 

```{r echo=FALSE}
Probas_ejercicio4=list()
for (i in 0:8){
  if(i==8){
    Probas_ejercicio4[i+1]=pbinom(i-1,n,p,lower.tail = FALSE)
  }else{
    Probas_ejercicio4[i+1]=dbinom(i,n,p)
  }
}
Probas_ejercicio4=unlist(Probas_ejercicio4)
print(Probas_ejercicio4)

```
Verificamos que las probas suman 1. 
$$\sum_{i=0}^{8} p_{i} = 1$$

```{r echo=TRUE}
sum(Probas_ejercicio4)
```
Ahora calculamos las frecuencias esperadas. 

$$n * p_{i}$$
```{r echo=TRUE}
ei= Probas_ejercicio4 * k 
print(ei)
```

Podemos visualizar toda la información. 

```{r echo=TRUE}
Tabla_ji = data.frame("ci"=0:8, "oi"=oi,"pi"= Probas_ejercicio4,"ei"=ei)
print(Tabla_ji)
```

Vamos a calcular nuestra estadística de prueba. 
$$T= \sum _{i=0}^{8} \frac{(o_{i}-e_{i})^{2}}{e_{i}}$$

```{r echo=TRUE}
EstJi=0 
for (i in 1:9){
  EstJi=EstJi+(((oi[i]) - (ei[i]))^2)/(ei[i])
}
print(EstJi)
```
Se comienza el ciclo desde 1 hasta 9 ya que son las entradas de los vectores, no son las clasificaciones. 

Para un nivel de confianza $\alpha = 0.01 $ tenemos que $1-\alpha = 0.99$. 

```{r echo=TRUE}
alpha_ejercicio4=0.01
conf_ejercicio4= 1- alpha_ejercicio4
```

Necesitamos los grados de libertad, que es el número de clasificaciones menos uno, ya que no estimamos parámetros. 

```{r echo=FALSE}
v= length(Probas_ejercicio4) -1
print(v)
```
Calculamos el cuantil ${\chi}^2_{8,\ 0.99}$.
```{r echo=TRUE}
valor_critico=qchisq(conf_ejercicio4,df=v,lower.tail = TRUE)
```
Comparamos la estadística de prueba con el valor crítico. 
```{r echo=TRUE}
Rechazamos_H0_p4=EstJi>valor_critico
print(Rechazamos_H0_p4)
```

No hay evidencia pra decir que los datos no siguien una distribución binomial con n=10 y p=0.25, entonces aceptamos Ho. 

Para comprobar los cálculos usemos la prueba que vienen en la libreria nortest. 

```{r echo=TRUE}
p_value_p4=chisq.test(x=oi,p=Probas_ejercicio4)[[3]]
Rechazamos_p_value_p4=alpha_ejercicio4>p_value_p4
print(Rechazamos_p_value_p4)
```
No rechazamos Ho. 

## Pruebas de bondad de ajuste
## Problema 5


En R fije la semilla 2019, y genera 25 observaciones distribuidas como una N(0; 1)
y con ella realiza:

Calcula y gráfica la función de distribución empírica de las observaciones
generadas.

Agrega sobre esa misma gráfica, la curva de la distribución verdadera (N(0; 1)).
A partir de las gráficas anteriores ¿La función de distribución empírica es
similar a la distribucin teórica de los datos?.

Vuelve a fijar la semilla 2019, y genera un millón de observaciones distribuidas como una N(0; 1) y con ello realiza:

Calcula y gráfica la función de distribución empírica de las observaciones generadas.

Agrega sobre esa misma gráfica, la curva de la distribución verdadera (N(0; 1)).
A partir de las gráficas anteriores ¿La función de distribución empírica es similar a la distribución teórica de los datos?.

Realiza la diferencia entre el valor de la función empírica y la función real,
(Hint: no olvides que debes ordenar de menor a mayor los valores de la distribución conocida y sólo mostrar los primeros 5 y los últimos 5 resultados)
¿Al ser una muestra mucho mayor que al anterior a que teorema te recuerda
el resultado obtenido?.


















